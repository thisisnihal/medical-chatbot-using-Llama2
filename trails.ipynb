{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiiiiiiii\n"
     ]
    }
   ],
   "source": [
    "print(\"Hiiiiiiii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV = os.getenv('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pdf \n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_data=load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247445/4238859041.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'deletion_protection': 'disabled',\n",
       "              'dimension': 384,\n",
       "              'host': 'medical-chatbot2-o7nzv1n.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'medical-chatbot2',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"medical-chatbot2\"\n",
    "\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_pinecone(chunks, batch_size, embeddings):\n",
    "    try:\n",
    "        texts = [chunk.page_content for chunk in chunks]\n",
    "        metadata = [{\"source\": chunk.metadata.get(\"source\", \"\"),\n",
    "                    \"page\": chunk.metadata.get(\"page\", 0)} for chunk in chunks]\n",
    "        \n",
    "        embeddings = embeddings.embed_documents(texts)\n",
    "        \n",
    "        # Prepare vectors with metadata\n",
    "        vectors = [\n",
    "            (str(i), emb, meta) \n",
    "            for i, (emb, meta) in enumerate(zip(embeddings, metadata))\n",
    "        ]\n",
    "        \n",
    "        # Upload in batches\n",
    "        for i in range(0, len(vectors), batch_size):\n",
    "            batch = vectors[i:i + batch_size]\n",
    "            index.upsert(vectors=[(id_, vec, meta) for id_, vec, meta in batch])\n",
    "            print(f\"Uploaded batch {i//batch_size + 1} of {len(vectors)//batch_size + 1}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to Pinecone: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1 of 8\n",
      "Uploaded batch 2 of 8\n",
      "Uploaded batch 3 of 8\n",
      "Uploaded batch 4 of 8\n",
      "Uploaded batch 5 of 8\n",
      "Uploaded batch 6 of 8\n",
      "Uploaded batch 7 of 8\n",
      "Uploaded batch 8 of 8\n"
     ]
    }
   ],
   "source": [
    "upload_to_pinecone(text_chunks, 1000, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [chunk.page_content for chunk in text_chunks]\n",
    "metadatas = [chunk.metadata for chunk in text_chunks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as LangChainPinecone\n",
    "docsearch = LangChainPinecone.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    index_name=index_name,\n",
    "    namespace=\"\"  # Optional: specify namespace if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_documents(query: str, k: int = 3):\n",
    "        try:\n",
    "            results = docsearch.similarity_search_with_score(query,k=k)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying documents: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.669756114\n",
      "Content: Psychosis —A serious mental disorder character-\n",
      "ized by defective or lost contact with reality oftenwith hallucinations or delusions.\n",
      "• aggitation\n",
      "• memory loss\n",
      "• confusion• dizziness\n",
      "• tiredness\n",
      "• headache• sleep disturbances\n",
      "• stuttering\n",
      "• dry skin• nausea\n",
      "• constipation\n",
      "•f e v e r• weight gain\n",
      "• visual disturbances\n",
      "Interactions\n",
      "Taking atypical antipsychotic medications with cer-...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.669322431\n",
      "Content: Psychosis —A serious mental disorder character-\n",
      "ized by defective or lost contact with reality oftenwith hallucinations or delusions.\n",
      "• aggitation\n",
      "• memory loss\n",
      "• confusion• dizziness\n",
      "• tiredness\n",
      "• headache• sleep disturbances\n",
      "• stuttering\n",
      "• dry skin• nausea\n",
      "• constipation\n",
      "•f e v e r• weight gain\n",
      "• visual disturbances\n",
      "Interactions\n",
      "Taking atypical antipsychotic medications with cer-...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.605602503\n",
      "Content: system, disorder which is characterized by abnor-mally cold hands and feet. This chilling effect iscaused by constriction of the blood vessels in theextremities, and occurs when the hands and feetare exposed to cold weather. Emotional stress canalso trigger the cold symptoms.\n",
      "Schizophrenia —Schizophrenia is a psychotic dis-\n",
      "order that causes distortions in perception (delu-sions and hallucinations), inappropriate moodsand behaviors, and disorganized or incoherentspeech and behavior....\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.605363429\n",
      "Content: system, disorder which is characterized by abnor-mally cold hands and feet. This chilling effect iscaused by constriction of the blood vessels in theextremities, and occurs when the hands and feetare exposed to cold weather. Emotional stress canalso trigger the cold symptoms.\n",
      "Schizophrenia —Schizophrenia is a psychotic dis-\n",
      "order that causes distortions in perception (delu-sions and hallucinations), inappropriate moodsand behaviors, and disorganized or incoherentspeech and behavior....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"schizophrenia disorder\"\n",
    "results = query_documents(query, 6)\n",
    "    \n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Content: {doc.page_content[:600]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following peices of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT= PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"] )\n",
    "chain_type_kwargs= {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_1.bin\",\n",
    "                   model_type=\"llama\",\n",
    "                   config={'max_new_tokens': 512,\n",
    "                            'temperature': 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm= llm,\n",
    "    chain_type= \"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k':2}),\n",
    "    return_source_documents= True,\n",
    "    chain_type_kwargs= chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  You can take over-the-counter pain relievers such as acetaminophen or ibuprofen to help reduce any discomfort or fever associated with a cold. Drinking plenty of fluids, getting enough rest, and using a humidifier to add moisture to the air can also help relieve symptoms. If your symptoms are severe or last longer than a week, you should consult a doctor for further treatment.\n"
     ]
    }
   ],
   "source": [
    "user_input=\"how to treat cold\"\n",
    "result=qa({\"query\": user_input})\n",
    "print(\"Response: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
